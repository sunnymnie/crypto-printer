{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07f5d2a",
   "metadata": {},
   "source": [
    "# Metrics Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f619e71",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a32a46",
   "metadata": {},
   "source": [
    "The general framework of hypothesis testing as applied to backtesting follows these steps:\n",
    "\n",
    "1. Based on a backtest on some finite sample of data, we compute a certain statistical measure called the **test statistic**.\n",
    "\n",
    "\n",
    "2. We suppose that t-statistic based on an infinite data set is actually zero.This supposition is called the null hypothesis.\n",
    "\n",
    "\n",
    "3. We suppose that the probability distribution of daily returns is known. This probability distribution has a zero mean, based on the null hypothesis. We describe later how we determine this probability distribution.\n",
    "\n",
    "\n",
    "4. Based on this null hypothesis probability distribution, we compute the probability p that the t-statistic will be at least as extreme (allowing for the possibility of a negative test statistic). This probability p is called the **p-value**, and if it is very small (let’s say smaller than 0.01), that means we can “reject the null hypothesis,” and conclude that the backtested average daily return is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ba1df",
   "metadata": {},
   "source": [
    "## Determining the Probability Distribution Under Null Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf99282",
   "metadata": {},
   "source": [
    "### Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854a86f",
   "metadata": {},
   "source": [
    "Suppose that the daily returns follow a Gaussian distribution, with a mean of zero and a standard deviation given by the sample standard deviation of the t-statistic. \n",
    "\n",
    "\n",
    "If we do this, it is clear that if the backtest has a high Sharpe ratio, it would be very easy for us to reject the null hypothesis. This is because the standard test statistic for a Gaussian distribution is none other than the average divided by the standard deviation and multiplied by the square root of the number of data points \n",
    "\n",
    "(basically fancy way of saying the sharpe ratio lmao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504915d",
   "metadata": {},
   "source": [
    "| p-value         | 0.1   | 0.05  | 0.01  | 0.001 |\n",
    "|-----------------|-------|-------|-------|-------|\n",
    "| Critical Values | 1.282 | 1.645 | 2.326 | 3.091 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b48a2",
   "metadata": {},
   "source": [
    "### Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a018dcc",
   "metadata": {},
   "source": [
    "Another method is to use Monte Carlo methods to generate simulated historical price data and feed these simulated data into our strategy to determine the empirical probability distribution of profits.\n",
    "\n",
    "\n",
    "Our belief is that the profitability of the trading strategy captured some subtle patterns or correlations of the price series, and not just because of the first few moments of the price distributions.\n",
    "\n",
    "\n",
    "So if we generate many simulated price series with the same first moments and the same length as the actual price data, and run the trading strategy over all these simulated price series, we can find out in what fraction p of these price series are the average returns greater than or equal to the backtest return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f50c6a",
   "metadata": {},
   "source": [
    "### Simulated Trades Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4b3c0",
   "metadata": {},
   "source": [
    "In this method, instead of generating simulated price data, we generate sets of simulated trades, with the constraint that the number of long and short entry trades is the same as in the backtest, and with the same average holding period for the trades. \n",
    "\n",
    "These trades are distributed randomly over the actual historical price series. We then measure what fraction of such sets of trades has average return greater than or equal to the backtest average return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3ba44",
   "metadata": {},
   "source": [
    "## Options for T-Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6be62",
   "metadata": {},
   "source": [
    "- Returns\n",
    "    - Cumulative Returns\n",
    "    - Average Daily Returns\n",
    "    \n",
    "    \n",
    "- Drawdown\n",
    "    - Maximum Drawdown Length\n",
    "    - Number of Drawdowns > 1 Week\n",
    "\n",
    "\n",
    "- Losses\n",
    "    - Number of 15% Losses\n",
    "    - Biggest Loss\n",
    "    \n",
    "**OR Some Combination of the Above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c7de8",
   "metadata": {},
   "source": [
    "# Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c9ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import math\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f0af6",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d582cfb",
   "metadata": {},
   "source": [
    "### Average Daily Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = #daily returns of strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we multiply by the sqrt(len(ret)) to \"annualize\" the sharpe ratio based on big brain maths\n",
    "sharpe = np.sqrt(len(ret)) * np.nanmean(ret) / np.nanstd(ret)\n",
    "print(\"Gaussian Test statistic = %f\" % sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e26f8e",
   "metadata": {},
   "source": [
    "| p-value         | 0.1   | 0.05  | 0.01  | 0.001 |\n",
    "|-----------------|-------|-------|-------|-------|\n",
    "| Critical Values | 1.282 | 1.645 | 2.326 | 3.091 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e0b1e",
   "metadata": {},
   "source": [
    "### Anything Else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8daed",
   "metadata": {},
   "source": [
    "(Basically like the sharpe ratio, but using params other than returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to base std off of (ex. for avg daily return, would be list of daily returns.\n",
    "# for max drawdown length, would be list of drawdown lengths)\n",
    "raw_value_list = \n",
    "\n",
    "#the raw value of the t-stat to test\n",
    "raw_value = \n",
    "\n",
    "#the null hypothesis value\n",
    "null_hypothesis = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3829509",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat = (raw_value - null_hypothesis) / np.nanstd(raw_value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cce12fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2816362297304775\n",
      "1.6450060180692423\n",
      "2.3267208386694755\n",
      "3.091047516030612\n"
     ]
    }
   ],
   "source": [
    "# Finding Critical Values\n",
    "# dof (degrees of freedom) is pretty much just a fancy way of saying n-1, (n=number of values in distribution)\n",
    "# theoretically infinite, since we are using a hypothetical gaussian distribution\n",
    "dof = 10000 \n",
    "\n",
    "print(st.t.ppf(q=1-(0.1),df=dof))\n",
    "print(st.t.ppf(q=1-(0.05),df=dof))\n",
    "print(st.t.ppf(q=1-(0.01),df=dof))\n",
    "print(st.t.ppf(q=1-(0.001),df=dof))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74a35c",
   "metadata": {},
   "source": [
    "## Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111e4b4",
   "metadata": {},
   "source": [
    "### Monte Carlo Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metric to use to measure the input data\n",
    "# for \"predict the market\" strategies, can be close price or market returns\n",
    "# can use z-score for this strategy\n",
    "zscore_metric = spread.zscore\n",
    "\n",
    "#daily returns of strategy\n",
    "ret = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfde8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_, loc_, scale_ = st.pearson3.fit(zscore_metric)\n",
    "num_better_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76940178",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "ret_sims = []\n",
    "\n",
    "for sample in tqdm(range(sample_size)):\n",
    "    zscore_sim = st.pearson3.rvs(skew=skew_, loc=loc_, scale=scale_, size=zscore_metric.shape[0], random_state=sample)\n",
    "    \n",
    "    spread_sim = spread\n",
    "    spread_sim['zscore'] = zscore_sim\n",
    "    \n",
    "    ret_sim = run_backtest(spread_sim, 1.5, .5)[0]\n",
    "    ret_sims.append(ret_sim)\n",
    "    \n",
    "    if (np.mean(ret_sim) >= np.mean(ret)):\n",
    "        num_better_samples += 1\n",
    "            \n",
    "print(\"Randomized zscore: p-value = %f\" % (num_better_samples / sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c74b9da",
   "metadata": {},
   "source": [
    "## Randomized Entry Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d21fa5",
   "metadata": {},
   "source": [
    "### Randomized Entry Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ac0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_better_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fac295",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "ret_sims = []\n",
    "\n",
    "for sample in tqdm(range(sample_size)):\n",
    "    long_a_sim = long_a.shuffle()\n",
    "    long_b_sim = long_b.shuffle() \n",
    "    \n",
    "    ret_sim = run_fake_backtest(spread, long_a_sim, long_b_sim, 1.5, 5)[0]\n",
    "    ret_sims.append(ret_sim)\n",
    "    \n",
    "    if (np.mean(ret_sim) >= np.mean(ret)):\n",
    "        num_better_samples += 1\n",
    "\n",
    "print(\"Randomized Entry: p-value = %f\" % (num_better_samples / sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48726d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_b(al, ac, ah, bl, bc, bh):\n",
    "    return ac-abs(ac-al)/2, ac+abs(ac-ah)/2, bc-abs(bc-bl)/2, bc+abs(bc-bh)/2\n",
    "\n",
    "def run_fake_backtest(spread, long_a_sim, long_b_sim, thres, sell_thres, fee=0.002, interest=0.002):\n",
    "    total, p_total = 0, 0 #Previous total\n",
    "    cusum, returns = [], []\n",
    "    price_a, price_b, long = None, None, None #Values: None, \"A\", \"B\"\n",
    "    long_a, long_b, liquidate,  dd_indices= [], [], [], [] #Drawdown indicies\n",
    "    dd_i = True\n",
    "    \n",
    "    for i in range(spread.shape[0]):\n",
    "        al, ah, bl, bh = get_a_b(spread.Al[i], spread.A[i], spread.Ah[i], spread.Bl[i], spread.B[i], spread.Bh[i])\n",
    "        \n",
    "        if i in long_a_sim: # Looking to buy\n",
    "            price_a = ah\n",
    "            price_b = bl\n",
    "            long = \"A\"\n",
    "            long_a.append(spread.index[i])\n",
    "            \n",
    "        elif i in long_b_sim:\n",
    "            price_a = al\n",
    "            price_b = bh\n",
    "            long = \"B\"\n",
    "            long_b.append(spread.index[i])\n",
    "            \n",
    "        elif (long == \"A\" and (i in long_b_sim)) or (long == \"B\" and (i in long_a_sim)): #Liquidate positions\n",
    "            al, ah, bl, bh = get_a_b(spread.Al[i], spread.A[i], spread.Ah[i], spread.Bl[i], spread.B[i], spread.Bh[i])\n",
    "            gain = 0\n",
    "            if long==\"A\":\n",
    "                gain = liquidate_assets(price_b, bh, al, price_a, fee, long_a[-1], spread.index[i], interest)\n",
    "            else:\n",
    "                gain = liquidate_assets(price_a, ah, bl, price_b, fee, long_b[-1], spread.index[i], interest)\n",
    "            returns.append(gain)\n",
    "            total += gain\n",
    "            price_a, price_b, long = None, None, None\n",
    "            liquidate.append(spread.index[i])\n",
    "        cusum.append(total)\n",
    "        \n",
    "\n",
    "        if total < p_total:\n",
    "            if dd_i:\n",
    "                dd_indices.append(spread.index[i])\n",
    "                dd_i = False\n",
    "        else:\n",
    "            if not dd_i:\n",
    "                dd_indices.append(spread.index[i])\n",
    "                dd_i = True\n",
    "            p_total = total\n",
    "    if total < p_total:\n",
    "        dd_indices.append(spread.index[i])\n",
    "    drawdowns = get_drawdowns(dd_indices)\n",
    "    return long_a, long_b, liquidate, cusum, returns, drawdowns\n",
    "        \n",
    "def liquidate_assets(x1, x2, y1, y2, fee, d1, d2, interest):\n",
    "    interest = ((d2-d1).days + 1) * interest\n",
    "    total = (x1 - x2)/x1 - 2*fee - interest\n",
    "    total += (y1 - y2)/y1 - 2*fee - interest\n",
    "    return total\n",
    "\n",
    "def get_drawdowns(dd_indices):\n",
    "    a = dd_indices[1::2]\n",
    "    b = dd_indices[::2]\n",
    "    a = np.array(a)\n",
    "    b = np.array(b[:len(a)])\n",
    "    c = a-b\n",
    "    c.sort()\n",
    "    return c[::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
